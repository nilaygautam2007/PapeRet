{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reconstruct the abstract from inverted index to plain text\n",
    "def reconstruct_abstract(abstract_inverted_index):\n",
    "    if not abstract_inverted_index:\n",
    "        return \"\"\n",
    "    \n",
    "    # Find the maximum position to determine the abstract length\n",
    "    max_pos = max(pos for positions in abstract_inverted_index.values() for pos in positions)\n",
    "    abstract_words = [\"\"] * (max_pos + 1)\n",
    "    \n",
    "    for word, positions in abstract_inverted_index.items():\n",
    "        for pos in positions:\n",
    "            abstract_words[pos] = word\n",
    "    \n",
    "    return \" \".join(abstract_words)\n",
    "\n",
    "# Function to fetch paper metadata using DOI\n",
    "def fetch_paper_metadata_by_doi(doi):\n",
    "    url = f\"https://api.openalex.org/works/https://doi.org/{doi}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for DOI: {doi} with status code {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Function to fetch paper metadata using OpenAlex ID\n",
    "def fetch_paper_metadata_by_openalex_id(openalex_id):\n",
    "    url = f\"https://api.openalex.org/works/{openalex_id}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for OpenAlex ID: {openalex_id} with status code {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# BFS to fetch references up to a specified depth\n",
    "def fetch_references_bfs(seed_dois, max_depth=2):\n",
    "    result = []\n",
    "    queue = deque([(doi, 0, \"doi\") for doi in seed_dois])  # Initialize queue with seed DOIs and depth 0, using \"doi\" for seed papers\n",
    "    visited = set()  # Track visited papers using DOIs and OpenAlex IDs\n",
    "\n",
    "    current_depth = 0\n",
    "    depth_queue = []  # To store elements of the current depth level for progress tracking\n",
    "\n",
    "    while queue and current_depth <= max_depth:\n",
    "        # Separate elements for the current depth\n",
    "        while queue and queue[0][1] == current_depth:\n",
    "            depth_queue.append(queue.popleft())\n",
    "        \n",
    "        # Create a new progress bar for the current depth\n",
    "        with tqdm(total=len(depth_queue), desc=f\"Processing Depth {current_depth}\") as pbar:\n",
    "\n",
    "            count=0\n",
    "            for current_id, depth, id_type in depth_queue:\n",
    "\n",
    "                count += 1\n",
    "\n",
    "                # Skip if the paper has already been visited\n",
    "                if current_id in visited:\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "\n",
    "                # Fetch metadata based on ID type\n",
    "                if id_type == \"doi\":\n",
    "                    paper_data = fetch_paper_metadata_by_doi(current_id)\n",
    "                else:\n",
    "                    paper_data = fetch_paper_metadata_by_openalex_id(current_id)\n",
    "\n",
    "                if not paper_data:\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "\n",
    "                # Mark the paper as visited\n",
    "                visited.add(current_id)\n",
    "\n",
    "                locations = paper_data.get(\"locations\", [])\n",
    "                location_info = [\n",
    "                    {\n",
    "                        \"venue_name\": loc.get(\"source\", {}).get(\"display_name\", \"Not Available\"),\n",
    "                        \"publisher\": loc.get(\"source\", {}).get(\"host_organization\", \"Not Available\"),\n",
    "                        # \"landing_page_url\": loc.get(\"landing_page_url\", \"Not Available\"),\n",
    "                        \"pdf_url\": loc.get(\"pdf_url\", \"Not Available\"),\n",
    "                        # \"version\": loc.get(\"version\", \"Not Available\"),\n",
    "                        # \"is_open_access\": loc.get(\"is_oa\", False),\n",
    "                        # \"license\": loc.get(\"license\", \"Not Available\"),\n",
    "                    }\n",
    "                    for loc in locations if loc.get('source', None) is not None\n",
    "                ]\n",
    "\n",
    "                # Structuring metadata for JSON format\n",
    "                paper_info = {\n",
    "                    \"title\": paper_data.get(\"title\", \"\"),\n",
    "                    \"doi_openalexid\": paper_data.get(\"doi\", \"\").replace(\"https://doi.org/\", \"\") if paper_data.get(\"doi\") else paper_data.get(\"id\", \"\"),\n",
    "                    \"authors\": [author['author']['display_name'] for author in paper_data.get(\"authorships\", [])],\n",
    "                    \"publication_date\": paper_data.get(\"publication_date\", \"\"),\n",
    "                    \"publish_year\": paper_data.get(\"publication_year\", \"\"),\n",
    "                    \"keywords\": [concept['display_name'] for concept in paper_data.get(\"concepts\", [])],\n",
    "                    \"abstract\": reconstruct_abstract(paper_data.get(\"abstract_inverted_index\", \"\")),\n",
    "                    \"global_link_openable\": paper_data.get(\"id\", \"\"),\n",
    "                    \"citation_count\": paper_data.get(\"cited_by_count\", 0),\n",
    "                    \"publication\": location_info,\n",
    "                    \"references_related_works\": [] ### TODO\n",
    "                }\n",
    "\n",
    "                # Process references using OpenAlex IDs\n",
    "                references = paper_data.get(\"referenced_works\", [])\n",
    "                if len(references) == 0:\n",
    "                    references = paper_data.get(\"related_works\", [])\n",
    "                for ref_id in references:\n",
    "                    if ref_id not in visited:\n",
    "                        queue.append((ref_id, depth + 1, \"openalex_id\"))  # Use OpenAlex ID for subsequent references\n",
    "                        paper_info[\"references_related_works\"].append({\"openalex_id\": ref_id}) ### TODO\n",
    "\n",
    "                result.append(paper_info)\n",
    "                pbar.update(1)  # Update progress for each paper processed\n",
    "                time.sleep(0.1)  # Delay to respect rate limits\n",
    "\n",
    "                # Save Intermediate Results for Depth >= 2:\n",
    "                if current_depth>1 and count%1000==0:\n",
    "                    filename = f'OpenAlex_Intermediate_Depth_{current_depth}.json'\n",
    "                    with open(filename, \"w\") as json_file:\n",
    "                        json.dump(result, json_file, indent=2)\n",
    "                    print('\\n')\n",
    "                    print(f'File for Depth-{current_depth}, Count-{count} : Saved')\n",
    "                    print(f'Number of Unique Papers at Depth-{current_depth}, Count-{count} (cummulative of all depths) : {len(result)}')\n",
    "                    print('\\n')\n",
    "\n",
    "        # Saving Intermediate Results for each depth\n",
    "        filename = f'OpenAlex_Intermediate_Depth_{current_depth}.json'\n",
    "        with open(filename, \"w\") as json_file:\n",
    "            json.dump(result, json_file, indent=2)\n",
    "        print('\\n')\n",
    "        print(f'File for Depth-{current_depth} : Saved')\n",
    "        print(f'Number of Unique Papers at Depth-{current_depth} (cummulative of all depths) : {len(result)}')\n",
    "        print('\\n')\n",
    "\n",
    "\n",
    "\n",
    "        # Move to the next depth level\n",
    "        current_depth += 1\n",
    "        depth_queue.clear()  # Clear depth_queue for the next depth\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Depth 0:   0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Depth 0: 100%|██████████| 25/25 [00:07<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "File for Depth-0 : Saved\n",
      "Number of Unique Papers at Depth-0 (cummulative of all depths) : 25\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Depth 1: 100%|██████████| 1085/1085 [06:26<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "File for Depth-1 : Saved\n",
      "Number of Unique Papers at Depth-1 (cummulative of all depths) : 1028\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Depth 2:   0%|          | 1000/297182 [04:57<26:00:27,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "File for Depth-2, Count-1000 : Saved\n",
      "Number of Unique Papers at Depth-2, Count-1000 (cummulative of all depths) : 1771\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Depth 2:   0%|          | 1046/297182 [05:13<19:33:05,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch data for OpenAlex ID: https://openalex.org/W2530816535 with status code 404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Depth 2:   0%|          | 1180/297182 [06:06<30:50:10,  2.67it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Titles of the papers:\n",
    "# 1. \"Attention Is All You Need\"\n",
    "# 2. \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\"\n",
    "# 3. \"Deep Residual Learning for Image Recognition\"\n",
    "# 4. \"Generative Adversarial Nets\"\n",
    "# 5. \"Adam: A Method for Stochastic Optimization\"\n",
    "# 6. \"YOLOv3: An Incremental Improvement\"\n",
    "# 7. \"Neural Architecture Search with Reinforcement Learning\"\n",
    "# 8. \"The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks\"\n",
    "# 9. \"Deep Learning for Natural Language Processing\"  XXX\n",
    "# 10. \"Deep Learning for Genomics: A Concise Overview\"\n",
    "# 11. \"Deep Learning for Healthcare: Review, Opportunities and Challenges\" XXX\n",
    "# 12. \"Deep Learning for Time Series Forecasting: The Electric Load Case\"\n",
    "# 13. \"Deep Learning for Image Super-Resolution: A Survey\" XXX\n",
    "# 14. \"Deep Learning for Anomaly Detection: A Survey\"\n",
    "# 15. \"Deep Learning for Recommender Systems: A Survey and New Perspectives\"\n",
    "# 16. \"YOLO9000: Better, Faster, Stronger\"\n",
    "# 17. \"EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks\"\n",
    "# 18. \"XLNet: Generalized Autoregressive Pretraining for Language Understanding\"\n",
    "# 19. \"RoBERTa: A Robustly Optimized BERT Pretraining Approach\"\n",
    "# 20. \"GPT-3: Language Models are Few-Shot Learners\"\n",
    "# 21. \"Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\"\n",
    "# 22. \"DALL·E: Creating Images from Text\"\n",
    "# 23. \"AlphaFold: A Solution to a 50-Year-Old Grand Challenge in Biology\"\n",
    "# 24. \"Neural Ordinary Differential Equations\"\n",
    "# 25. \"StyleGAN: A Style-Based Generator Architecture for Generative Adversarial Networks\"\n",
    "# 26. \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\"\n",
    "# 27. \"Deep Learning for Large-Scale Hierarchical Image Database\" XXX\n",
    "# 28. \"Deep Learning for Machine Translation by Jointly Learning to Align and Translate\"\n",
    "# 29. \"Playing Atari with Deep Reinforcement Learning\" XXX\n",
    "# 30. \"EfficientNet: Model Scaling for Convolutional Neural Networks\"\n",
    "\n",
    "seed_dois = [\n",
    "    \"10.48550/arXiv.1706.03762\",\n",
    "    \"10.18653/v1/N19-1423\",\n",
    "    \"10.1109/CVPR.2016.90\",\n",
    "    \"10.48550/arXiv.1406.2661\",\n",
    "    \"10.48550/arXiv.1412.6980\",\n",
    "    \"10.48550/arXiv.1804.02767\",\n",
    "    \"10.48550/arXiv.1611.01578\",\n",
    "    \"10.48550/arXiv.1803.03635\",\n",
    "    # \"10.2200/S00762ED1V01Y201501HLT027\", # XXX\n",
    "    \"10.1016/j.patcog.2019.107107\",\n",
    "    # \"10.1007/s10115-018-1149-0\", # XXX\n",
    "    \"10.1016/j.ijforecast.2016.01.001\",\n",
    "    # \"10.1109/TNNLS.2020.2966520\", # XXX\n",
    "    \"10.1145/3236009\",\n",
    "    \"10.1145/3285029\",\n",
    "    \"10.1109/CVPR.2017.690\",\n",
    "    \"10.48550/arXiv.1905.11946\",\n",
    "    \"10.48550/arXiv.1906.08237\",\n",
    "    \"10.48550/arXiv.1907.11692\",\n",
    "    \"10.48550/arXiv.2005.14165\",\n",
    "    \"10.48550/arXiv.2103.14030\",\n",
    "    \"10.48550/arXiv.2102.12092\",\n",
    "    \"10.1038/s41586-021-03819-2\",\n",
    "    \"10.48550/arXiv.1806.07366\",\n",
    "    \"10.1109/CVPR.2019.00453\",\n",
    "    \"10.1109/CVPR.2018.00727\",\n",
    "    # \"10.48550/arXiv.1705.08436\", # XXX\n",
    "    \"10.1109/CVPR.2017.424\",\n",
    "    # \"10.1109/TPAMI.2018.2844859\", # XXX\n",
    "    \"10.1109/CVPR.2019.00020\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "max_depth = 2\n",
    "data = fetch_references_bfs(seed_dois, max_depth=max_depth)\n",
    "\n",
    "with open(\"openalex_papers.json\", \"w\") as json_file:\n",
    "    json.dump(data, json_file, indent=2)\n",
    "print('Data Saved.')\n",
    "\n",
    "print(f'Number of Unique Papers = {len(data)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
