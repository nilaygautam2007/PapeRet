{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from collections import deque\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reconstruct the abstract from inverted index to plain text\n",
    "def reconstruct_abstract(abstract_inverted_index):\n",
    "    if not abstract_inverted_index:\n",
    "        return \"\"\n",
    "    \n",
    "    # Find the maximum position to determine the abstract length\n",
    "    max_pos = max(pos for positions in abstract_inverted_index.values() for pos in positions)\n",
    "    abstract_words = [\"\"] * (max_pos + 1)\n",
    "    \n",
    "    for word, positions in abstract_inverted_index.items():\n",
    "        for pos in positions:\n",
    "            abstract_words[pos] = word\n",
    "    \n",
    "    return \" \".join(abstract_words)\n",
    "\n",
    "# Function to fetch paper metadata using DOI\n",
    "def fetch_paper_metadata_by_doi(doi):\n",
    "    url = f\"https://api.openalex.org/works/https://doi.org/{doi}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for DOI: {doi} with status code {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Function to fetch paper metadata using OpenAlex ID\n",
    "def fetch_paper_metadata_by_openalex_id(openalex_id):\n",
    "    url = f\"https://api.openalex.org/works/{openalex_id}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for OpenAlex ID: {openalex_id} with status code {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# BFS to fetch references up to a specified depth\n",
    "def fetch_references_bfs(seed_dois, max_depth=2):\n",
    "    result = []\n",
    "    queue = deque([(doi, 0, \"doi\") for doi in seed_dois])  # Initialize queue with seed DOIs and depth 0, using \"doi\" for seed papers\n",
    "    visited = set(seed_dois)\n",
    "\n",
    "    current_depth = 0\n",
    "    depth_queue = []  # To store elements of the current depth level for progress tracking\n",
    "\n",
    "    while queue and current_depth <= max_depth:\n",
    "        # Separate elements for the current depth\n",
    "        while queue and queue[0][1] == current_depth:\n",
    "            depth_queue.append(queue.popleft())\n",
    "        \n",
    "        # Create a new progress bar for the current depth\n",
    "        with tqdm(total=len(depth_queue), desc=f\"Processing Depth {current_depth}\") as pbar:\n",
    "            for current_id, depth, id_type in depth_queue:\n",
    "                # Fetch metadata based on ID type\n",
    "                if id_type == \"doi\":\n",
    "                    paper_data = fetch_paper_metadata_by_doi(current_id)\n",
    "                else:\n",
    "                    paper_data = fetch_paper_metadata_by_openalex_id(current_id)\n",
    "\n",
    "                if not paper_data:\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "\n",
    "                # Structuring metadata for JSON format\n",
    "                paper_info = {\n",
    "                    \"title\": paper_data.get(\"title\", \"\"),\n",
    "                    \"doi_openalexid\": paper_data.get(\"doi\", \"\").replace(\"https://doi.org/\", \"\") if paper_data.get(\"doi\") else paper_data.get(\"id\", \"\"),\n",
    "                    \"authors\": [author['author']['display_name'] for author in paper_data.get(\"authorships\", [])],\n",
    "                    \"publication_date\": paper_data.get(\"publication_date\", \"\"),\n",
    "                    \"publish_year\": paper_data.get(\"publication_year\", \"\"),\n",
    "                    \"keywords\": [concept['display_name'] for concept in paper_data.get(\"concepts\", [])],\n",
    "                    \"abstract\": reconstruct_abstract(paper_data.get(\"abstract_inverted_index\", \"\")),\n",
    "                    \"global_link_openable\": paper_data.get(\"id\", \"\"),\n",
    "                    \"citation_count\": paper_data.get(\"cited_by_count\", 0),\n",
    "                    \"references\": []\n",
    "                }\n",
    "\n",
    "                # Process references using OpenAlex IDs\n",
    "                references = paper_data.get(\"referenced_works\", [])\n",
    "                for ref_id in references:\n",
    "                    if ref_id not in visited:\n",
    "                        visited.add(ref_id)\n",
    "                        queue.append((ref_id, depth + 1, \"openalex_id\"))  # Use OpenAlex ID for subsequent references\n",
    "                        paper_info[\"references\"].append({\"openalex_id\": ref_id})\n",
    "\n",
    "                result.append(paper_info)\n",
    "                pbar.update(1)  # Update progress for each paper processed\n",
    "                time.sleep(1)  # Delay to respect rate limits\n",
    "\n",
    "        # Move to the next depth level\n",
    "        current_depth += 1\n",
    "        depth_queue.clear()  # Clear depth_queue for the next depth\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Depth 0:  30%|███       | 9/30 [00:11<00:29,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch data for DOI: 10.2200/S00762ED1V01Y201501HLT027 with status code 404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Depth 0:  37%|███▋      | 11/30 [00:13<00:22,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch data for DOI: 10.1007/s10115-018-1149-0 with status code 404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Depth 0:  43%|████▎     | 13/30 [00:14<00:18,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch data for DOI: 10.1109/TNNLS.2020.2966520 with status code 404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Depth 0:  90%|█████████ | 27/30 [00:34<00:04,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch data for DOI: 10.48550/arXiv.1705.08436 with status code 404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Depth 0:  97%|█████████▋| 29/30 [00:37<00:01,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch data for DOI: 10.1109/TPAMI.2018.2844859 with status code 404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Depth 0: 100%|██████████| 30/30 [00:38<00:00,  1.28s/it]\n",
      "Processing Depth 1:  77%|███████▋  | 702/913 [22:43<07:40,  2.18s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Titles of the papers:\n",
    "# 1. \"Attention Is All You Need\"\n",
    "# 2. \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\"\n",
    "# 3. \"Deep Residual Learning for Image Recognition\"\n",
    "# 4. \"Generative Adversarial Nets\"\n",
    "# 5. \"Adam: A Method for Stochastic Optimization\"\n",
    "# 6. \"YOLOv3: An Incremental Improvement\"\n",
    "# 7. \"Neural Architecture Search with Reinforcement Learning\"\n",
    "# 8. \"The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks\"\n",
    "# 9. \"Deep Learning for Natural Language Processing\"  XXX\n",
    "# 10. \"Deep Learning for Genomics: A Concise Overview\"\n",
    "# 11. \"Deep Learning for Healthcare: Review, Opportunities and Challenges\" XXX\n",
    "# 12. \"Deep Learning for Time Series Forecasting: The Electric Load Case\"\n",
    "# 13. \"Deep Learning for Image Super-Resolution: A Survey\" XXX\n",
    "# 14. \"Deep Learning for Anomaly Detection: A Survey\"\n",
    "# 15. \"Deep Learning for Recommender Systems: A Survey and New Perspectives\"\n",
    "# 16. \"YOLO9000: Better, Faster, Stronger\"\n",
    "# 17. \"EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks\"\n",
    "# 18. \"XLNet: Generalized Autoregressive Pretraining for Language Understanding\"\n",
    "# 19. \"RoBERTa: A Robustly Optimized BERT Pretraining Approach\"\n",
    "# 20. \"GPT-3: Language Models are Few-Shot Learners\"\n",
    "# 21. \"Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\"\n",
    "# 22. \"DALL·E: Creating Images from Text\"\n",
    "# 23. \"AlphaFold: A Solution to a 50-Year-Old Grand Challenge in Biology\"\n",
    "# 24. \"Neural Ordinary Differential Equations\"\n",
    "# 25. \"StyleGAN: A Style-Based Generator Architecture for Generative Adversarial Networks\"\n",
    "# 26. \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\"\n",
    "# 27. \"Deep Learning for Large-Scale Hierarchical Image Database\" XXX\n",
    "# 28. \"Deep Learning for Machine Translation by Jointly Learning to Align and Translate\"\n",
    "# 29. \"Playing Atari with Deep Reinforcement Learning\" XXX\n",
    "# 30. \"EfficientNet: Model Scaling for Convolutional Neural Networks\"\n",
    "\n",
    "seed_dois = [\n",
    "    \"10.48550/arXiv.1706.03762\",\n",
    "    \"10.18653/v1/N19-1423\",\n",
    "    \"10.1109/CVPR.2016.90\",\n",
    "    \"10.48550/arXiv.1406.2661\",\n",
    "    \"10.48550/arXiv.1412.6980\",\n",
    "    \"10.48550/arXiv.1804.02767\",\n",
    "    \"10.48550/arXiv.1611.01578\",\n",
    "    \"10.48550/arXiv.1803.03635\",\n",
    "    \"10.2200/S00762ED1V01Y201501HLT027\",\n",
    "    \"10.1016/j.patcog.2019.107107\",\n",
    "    \"10.1007/s10115-018-1149-0\",\n",
    "    \"10.1016/j.ijforecast.2016.01.001\",\n",
    "    \"10.1109/TNNLS.2020.2966520\",\n",
    "    \"10.1145/3236009\",\n",
    "    \"10.1145/3285029\",\n",
    "    \"10.1109/CVPR.2017.690\",\n",
    "    \"10.48550/arXiv.1905.11946\",\n",
    "    \"10.48550/arXiv.1906.08237\",\n",
    "    \"10.48550/arXiv.1907.11692\",\n",
    "    \"10.48550/arXiv.2005.14165\",\n",
    "    \"10.48550/arXiv.2103.14030\",\n",
    "    \"10.48550/arXiv.2102.12092\",\n",
    "    \"10.1038/s41586-021-03819-2\",\n",
    "    \"10.48550/arXiv.1806.07366\",\n",
    "    \"10.1109/CVPR.2019.00453\",\n",
    "    \"10.1109/CVPR.2018.00727\",\n",
    "    \"10.48550/arXiv.1705.08436\",\n",
    "    \"10.1109/CVPR.2017.424\",\n",
    "    \"10.1109/TPAMI.2018.2844859\",\n",
    "    \"10.1109/CVPR.2019.00020\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "max_depth = 2\n",
    "data = fetch_references_bfs(seed_dois, max_depth=max_depth)\n",
    "\n",
    "import json\n",
    "# print(json.dumps(data, indent=2))\n",
    "with open(\"openalex_papers.json\", \"w\") as json_file:\n",
    "    json.dump(data, json_file, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
